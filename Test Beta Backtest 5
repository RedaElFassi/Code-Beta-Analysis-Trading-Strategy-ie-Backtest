# =========================
# Imports
# =========================
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.dates as mdates
from matplotlib.colors import Normalize
import statsmodels.api as sm

# =========================
# Paramètres généraux (UNE SEULE fenêtre pour analyse & backtest)
# =========================
COUNTRY_HIGH  = "Italy"
COUNTRY_LOW   = "Germany"
BENCHMARK_CURVE_COUNTRY = "Germany"

MATU_LONG  = "10Y"
MATU_SHORT = "5Y"
MATU_SPREAD = "10Y"      # maturité du SPREAD pour OLS & backtest

# Fenêtres (en NOMBRE D'OBSERVATIONS)
ROLLING_WINDOW_DAYS = 126    # ex: 63 / 126 / 252
OBS_WINDOW_DAYS     = 21     # 1 "mois" = 21 obs (cooldown)
HOLDING_DAYS        = 21     # max de détention (en obs)

# Seuils & notionnel (backtest)
RESID_THRESHOLD     = 2.0    # |epsilon| pour entrer
R2_ENTRY_THRESHOLD  = 0.30   # filtre qualité
TP_MULT             = 0.5    # TP = 0.5*threshold (en pts de BOX)
SL_MULT             = 0.5
DV01_K              = 10.0   # 10 => 10 k€

# Driver pour backtest (sur NIVEAUX)
DRIVER_FOR_SIGNAL   = "SPREAD"  # "SPREAD" ou "CURVE"


# =========================
# Helpers noms/colonnes
# =========================
def _col(country, matu):
    return f"{country} {matu}"

def _safe_name(x):
    return x.replace(" ", "_")

def _col_bps(country, matu):
    return f"{_safe_name(country)}_{matu}_bps"


# =========================
# 1) MASTER unique (tout centralisé)
# =========================
def build_master_dataframe(
    data,
    country_high=COUNTRY_HIGH,
    country_low=COUNTRY_LOW,
    matu_long=MATU_LONG,
    matu_short=MATU_SHORT,
    matu_spread=MATU_SPREAD,
    curve_country=BENCHMARK_CURVE_COUNTRY,
    window=ROLLING_WINDOW_DAYS
):
    """
    Construit un DataFrame `master` avec:
      - Taux nécessaires convertis en bps (data en % → *100).
      - Séries dérivées (BOX_bps, SPREAD_bps, CURVE_bps) + daily changes (dBOX_bps, dSPREAD_bps, dCURVE_bps).
      - Rolling OLS (fenêtre = `window`) pour:
          * NIVEAUX:  BOX ~ SPREAD, BOX ~ CURVE
          * DAILY Δ:  dBOX ~ dSPREAD, dBOX ~ dCURVE
        Chacune écrit: alpha/beta/r2/tstat/resid, suffixées `_w{window}`.
    """
    if not isinstance(data.index, pd.DatetimeIndex):
        data = data.copy()
        data.index = pd.to_datetime(data.index)
    data = data.sort_index()

    master = pd.DataFrame(index=data.index)

    # Colonnes requises
    cols_needed = [
        _col(country_high, matu_long),
        _col(country_low,  matu_long),
        _col(country_high, matu_short),
        _col(country_low,  matu_short),
        _col(country_high, matu_spread),
        _col(country_low,  matu_spread),
        _col(curve_country, matu_long),
        _col(curve_country, matu_short),
    ]
    missing = [c for c in cols_needed if c not in data.columns]
    if missing:
        raise KeyError(f"Colonnes manquantes dans `data`: {missing}")

    # 1) Taux en bps (data en % → *100)
    master[_col_bps(country_high, matu_long)]  = data[_col(country_high, matu_long)].astype(float)  * 100.0
    master[_col_bps(country_low,  matu_long)]  = data[_col(country_low,  matu_long)].astype(float)  * 100.0
    master[_col_bps(country_high, matu_short)] = data[_col(country_high, matu_short)].astype(float) * 100.0
    master[_col_bps(country_low,  matu_short)] = data[_col(country_low,  matu_short)].astype(float) * 100.0

    # 2) Séries dérivées en bps
    master["BOX_bps"] = (
        master[_col_bps(country_high, matu_long)] - master[_col_bps(country_low,  matu_long)]
        - (master[_col_bps(country_high, matu_short)] - master[_col_bps(country_low,  matu_short)])
    )
    master["SPREAD_bps"] = (data[_col(country_high, matu_spread)].astype(float)
                            - data[_col(country_low, matu_spread)].astype(float)) * 100.0
    master["CURVE_bps"]  = (data[_col(curve_country, matu_long)].astype(float)
                            - data[_col(curve_country, matu_short)].astype(float)) * 100.0

    # 3) Daily changes
    master["dBOX_bps"]    = master["BOX_bps"].diff()
    master["dSPREAD_bps"] = master["SPREAD_bps"].diff()
    master["dCURVE_bps"]  = master["CURVE_bps"].diff()

    # 4) Rolling OLS writer
    def _rolling_ols_write(ycol, xcol, w, prefix):
        """
        OLS glissante y ~ const + x sur `w` obs.
        Écrit: {prefix}_alpha_w{w}, _beta_w{w}, _r2_w{w}, _tstat_w{w}, _resid_w{w}
        Aligné sur la date de fin de fenêtre.
        """
        y = master[ycol]
        x = master[xcol]
        df = pd.concat([y.rename("y"), x.rename("x")], axis=1).dropna()
        # colonnes vides pour toute la timeline (seront remplies aux dates fin-fenêtre)
        for suff in ["alpha","beta","r2","tstat","resid"]:
            master[f"{prefix}_{suff}_w{w}"] = np.nan

        if len(df) < w:
            return

        yv = df["y"].values
        xv = df["x"].values
        dfi = df.index  # dates sans NaN

        out_alpha, out_beta, out_r2, out_tstat, out_resid, out_dates = [], [], [], [], [], []

        for end in range(w, len(df) + 1):
            start = end - w
            y_w = yv[start:end]; x_w = xv[start:end]
            X = sm.add_constant(x_w, has_constant='add')
            res = sm.OLS(y_w, X).fit()

            last_y = y_w[-1]; last_x = x_w[-1]
            yhat_last = res.params[0] + res.params[1] * last_x

            out_dates.append(dfi[end-1])
            out_alpha.append(float(res.params[0]))
            out_beta.append(float(res.params[1]))
            out_r2.append(float(res.rsquared))
            out_tstat.append(float(res.tvalues[1]))
            out_resid.append(float(last_y - yhat_last))

        rr = pd.DataFrame({
            "alpha": out_alpha, "beta": out_beta, "r2": out_r2,
            "tstat": out_tstat, "resid": out_resid
        }, index=pd.Index(out_dates, name="Date"))

        master.loc[rr.index, f"{prefix}_alpha_w{w}"] = rr["alpha"]
        master.loc[rr.index, f"{prefix}_beta_w{w}"]  = rr["beta"]
        master.loc[rr.index, f"{prefix}_r2_w{w}"]    = rr["r2"]
        master.loc[rr.index, f"{prefix}_tstat_w{w}"] = rr["tstat"]
        master.loc[rr.index, f"{prefix}_resid_w{w}"] = rr["resid"]

    # 5) Calcul RR (UNE fenêtre = window)
    w = int(window)
    # NIVEAUX
    _rolling_ols_write("BOX_bps",  "SPREAD_bps", w, "lvl_spread")
    _rolling_ols_write("BOX_bps",  "CURVE_bps",  w, "lvl_curve")
    # DAILY CHANGES
    _rolling_ols_write("dBOX_bps", "dSPREAD_bps", w, "chg_spread")
    _rolling_ols_write("dBOX_bps", "dCURVE_bps",  w, "chg_curve")

    return master


# =========================
# 2) PLOTS — Timeseries & Scatter (style heatmap année)
# =========================
def plot_rr_timeseries(master, kind, driver, window, title_prefix):
    """
    Timeseries 4 panneaux: R², Beta, T-stat, Residual.
      kind   in {"lvl","chg"}
      driver in {"spread","curve"}
      window = int
    """
    k = str(kind).lower()
    d = str(driver).lower()
    w = int(window)
    cols = [
        f"{k}_{d}_r2_w{w}",
        f"{k}_{d}_beta_w{w}",
        f"{k}_{d}_tstat_w{w}",
        f"{k}_{d}_resid_w{w}",
    ]
    for c in cols:
        if c not in master.columns:
            print(f"[plot_rr_timeseries] Manque {c}"); return
    df = master[cols].dropna(how="all")
    if df.empty:
        print("[plot_rr_timeseries] Rien à tracer"); return

    fig, axes = plt.subplots(2, 2, figsize=(24, 12))
    fig.suptitle(title_prefix, fontsize=18, fontweight="bold", y=0.98)

    axes[0,0].plot(df.index, df[cols[0]], label="R²");        axes[0,0].set_title("R²"); axes[0,0].legend(); axes[0,0].grid(True)
    axes[0,1].plot(df.index, df[cols[1]], label="Beta");      axes[0,1].set_title("Beta"); axes[0,1].legend(); axes[0,1].grid(True)
    axes[1,0].plot(df.index, df[cols[2]], label="T-stat");    axes[1,0].set_title("T-stat"); axes[1,0].legend(); axes[1,0].grid(True)
    axes[1,1].plot(df.index, df[cols[3]], label="Residual");  axes[1,1].set_title("Residual (window end)"); axes[1,1].legend(); axes[1,1].grid(True)

    for ax in axes.flat:
        ax.xaxis.set_major_locator(mdates.YearLocator())
        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
        plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    plt.tight_layout(rect=[0, 0, 1, 0.95]); plt.show()


def plot_scatter_beta_year_heat(master, kind, driver, window, x_on, r2_min=None, title=None, x_label=None):
    """
    Scatter Beta vs NIVEAU (x_on = "SPREAD_bps" ou "CURVE_bps"), coloré par année (style heatmap).
      - `kind`   ∈ {"lvl","chg"}   (d'où vient Beta)
      - `driver` ∈ {"spread","curve"} (quelle OLS a produit Beta)
      - `window` int
      - `x_on`   "SPREAD_bps" | "CURVE_bps"
      - `r2_min` optionnel: filtre sur R²
    """
    k = str(kind).lower(); d = str(driver).lower(); w = int(window)
    beta_col = f"{k}_{d}_beta_w{w}"
    r2_col   = f"{k}_{d}_r2_w{w}"

    if beta_col not in master.columns:
        print(f"[plot_scatter_beta_year_heat] Manque {beta_col}"); return
    if x_on not in master.columns:
        print(f"[plot_scatter_beta_year_heat] Manque {x_on}"); return

    df = master[[beta_col, r2_col, x_on]].dropna()
    if r2_min is not None:
        df = df[df[r2_col] >= float(r2_min)]
    if df.empty:
        print("[plot_scatter_beta_year_heat] Rien à tracer"); return

    years = df.index.year
    cmap = cm.get_cmap("coolwarm")
    norm = Normalize(vmin=years.min(), vmax=years.max())

    plt.figure(figsize=(10,6))
    plt.scatter(df[x_on], df[beta_col], c=[cmap(norm(y)) for y in years], s=18)
    cbar = plt.colorbar(cm.ScalarMappable(norm=norm, cmap=cmap))
    cbar.set_label("Year")
    plt.xlabel(x_label if x_label else x_on)
    plt.ylabel("Beta")
    plt.title(title if title else f"Beta ({k.upper()}~{d.upper()}) vs {x_on}")
    plt.grid(True, alpha=0.35)
    plt.show()


def plot_box_level(master, title_suffix=""):
    if "BOX_bps" not in master.columns:
        print("[plot_box_level] 'BOX_bps' absent."); return
    plt.figure(figsize=(12,5))
    plt.plot(master.index, master["BOX_bps"], linewidth=1.6, label="BOX (bps)")
    plt.title(f"BOX level over time {title_suffix}")
    plt.xlabel("Date"); plt.ylabel("BOX (bps)")
    ax = plt.gca()
    ax.xaxis.set_major_locator(mdates.YearLocator())
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))
    plt.setp(ax.get_xticklabels(), rotation=45, ha='right')
    plt.grid(True, alpha=0.3); plt.legend(); plt.tight_layout(); plt.show()


# =========================
# 3) BACKTEST — basé 100% sur master
# =========================
def _first_cross(delta_series, tp, sl, side):
    """
    Cherche la 1ère date où ΔBOX touche TP/SL (sinon TIME au dernier point).
      side=+1 (LONG_BOX): TP si Δ<=-tp ; SL si Δ>=+sl
      side=-1 (SHORT_BOX): TP si Δ>=+tp ; SL si Δ<=-sl
    """
    for dt, d in delta_series.items():
        if side == +1:
            if d <= -tp: return dt, "TP"
            if d >=  sl: return dt, "SL"
        else:
            if d >=  tp: return dt, "TP"
            if d <= -sl: return dt, "SL"
    return delta_series.index[-1], "TIME"


def backtest_from_master(
    master,
    obs_window_days=OBS_WINDOW_DAYS,
    holding_days=HOLDING_DAYS,
    resid_threshold=RESID_THRESHOLD,
    r2_entry_threshold=R2_ENTRY_THRESHOLD,
    tp_mult=TP_MULT,
    sl_mult=SL_MULT,
    dv01_k=DV01_K,
    driver=DRIVER_FOR_SIGNAL
):
    """
    Backtest qui réutilise Alpha/Beta/R² de la RR niveaux (fenêtre = ROLLING_WINDOW_DAYS).
      - t0 = dates où RR (alpha/beta/r2) existent (fin de fenêtre TRAIN).
      - entry = rr_dates[i + OBS_WINDOW_DAYS]  (déplacement **dans rr_dates**, donc dates valides uniquement).
      - epsilon_t = BOX_t - (Alpha(t0) + Beta(t0)*X_t), X_t = SPREAD_bps ou CURVE_bps à l’entrée.
      - entrée si |epsilon|>=seuil ET R²(t0)>=r2_entry_threshold.
      - sortie via TP/SL/TIME sur les `holding_days` obs suivantes.
      - PnL = -side*(ExitBox - EntryBox)*dv01_k  (side=+1 LONG gagne si BOX ↓)

    Retour:
      - trades_df  (trié par Entry; cumuls “by entry” + “by exit”)
      - pnl_tracker (time-series MtM: colonnes Trade_i + CumPnL) — **sans NaN**.
    """
    d = driver.upper()  # "SPREAD" / "CURVE"
    w = int(ROLLING_WINDOW_DAYS)

    alpha_col = f"lvl_{d.lower()}_alpha_w{w}"
    beta_col  = f"lvl_{d.lower()}_beta_w{w}"
    r2_col    = f"lvl_{d.lower()}_r2_w{w}"
    x_col     = f"{d}_bps"
    y_col     = "BOX_bps"

    need = [alpha_col, beta_col, r2_col, x_col, y_col]
    for c in need:
        if c not in master.columns:
            raise KeyError(f"[backtest_from_master] Colonne manquante: {c}")

    idx = master.index

    # t0 = dates où alpha/beta/r2 existent (donc fin de fenêtre TRAIN)
    valid_mask = master[[alpha_col, beta_col, r2_col]].notna().all(axis=1)
    rr_dates = master.index[valid_mask].sort_values()
    if len(rr_dates) == 0:
        return pd.DataFrame(), pd.DataFrame()

    trades = []

    # Boucle sur les fins de fenêtres (triées naturellement)
    # >>> IMPORTANT: entry = rr_dates[i + obs_window_days] (déplacement dans rr_dates)
    for i in range(0, len(rr_dates) - obs_window_days):
        t0 = rr_dates[i]
        entry_date = rr_dates[i + obs_window_days]

        # Lire niveaux à l'entrée
        if entry_date not in idx:
            continue
        x_t = master.at[entry_date, x_col]
        y_t = master.at[entry_date, y_col]
        if pd.isna(x_t) or pd.isna(y_t):
            continue

        # Paramètres "gelés" au t0
        alpha_t0 = master.at[t0, alpha_col]
        beta_t0  = master.at[t0, beta_col]
        r2_t0    = master.at[t0, r2_col]
        if pd.isna(alpha_t0) or pd.isna(beta_t0) or pd.isna(r2_t0):
            continue

        # Résiduel + filtre
        y_hat_t = float(alpha_t0) + float(beta_t0) * float(x_t)
        resid_t = float(y_t) - y_hat_t
        if (abs(resid_t) < float(resid_threshold)) or (float(r2_t0) < float(r2_entry_threshold)):
            continue

        side = +1 if resid_t > 0 else -1
        entry_box = float(y_t)

        # Fenêtre (entry; entry+holding] — sur l'index complet dispo
        entry_pos = idx.get_loc(entry_date)
        exit_pos_lim = min(entry_pos + holding_days, len(idx) - 1)
        path = master.iloc[entry_pos+1: exit_pos_lim+1][y_col].dropna()

        if len(path) == 0:
            exit_date = entry_date
            exit_box  = entry_box
            reason    = "TIME"
        else:
            delta = path - entry_box
            tp = float(tp_mult) * float(resid_threshold)
            sl = float(sl_mult) * float(resid_threshold)
            exit_date, reason = _first_cross(delta, tp, sl, side)
            exit_box = float(master.at[exit_date, y_col])

        pnl = -side * (exit_box - entry_box) * float(dv01_k)

        trades.append({
            "Entry": entry_date,
            "Exit": exit_date,
            "Side": "LONG_BOX" if side == +1 else "SHORT_BOX",
            "EntryBox": entry_box,
            "Predicted": float(y_hat_t),
            "Residual": float(resid_t),
            "Beta": float(beta_t0),
            "R2": float(r2_t0),
            "Reason": reason,
            "ExitBox": exit_box,
            "PnL": float(pnl)
        })

    trades_df = pd.DataFrame(trades)
    if trades_df.empty:
        return trades_df, pd.DataFrame()

    # (A) Tri par Entry (et Exit pour stabiliser si égalité)
    trades_df = trades_df.sort_values(["Entry", "Exit"]).reset_index(drop=True)

    # (B) Cumuls “by entry” et “by exit” (on garde l'ordre par Entry dans le DataFrame)
    trades_df["RealizedCumPnL_by_entry"] = trades_df["PnL"].cumsum()
    exit_order = trades_df.sort_values("Exit").index
    cum_by_exit = trades_df.loc[exit_order, "PnL"].cumsum().values
    trades_df["RealizedCumPnL_by_exit"] = np.nan
    trades_df.loc[exit_order, "RealizedCumPnL_by_exit"] = cum_by_exit

    # (C) PnL tracker (MtM) — **sans NaN**, index = toutes les dates du portefeuille
    start_all = trades_df["Entry"].min()
    end_all   = trades_df["Exit"].max()
    dates = master.loc[(master.index >= start_all) & (master.index <= end_all)].index
    pnl_tracker = pd.DataFrame(index=dates)

    # numéroter selon l'ordre d'entrée
    for i, row in trades_df.iterrows():
        entry = row["Entry"]; exit_ = row["Exit"]
        side  = +1 if row["Side"] == "LONG_BOX" else -1
        entry_box = float(row["EntryBox"])

        # MtM = 0 le jour d'entrée; MtM = -side*(BOX - entry_box)*DV01_K sur (entry; exit]
        path = master.loc[(master.index > entry) & (master.index <= exit_), y_col].dropna()
        mtm = -side * (path - entry_box) * float(dv01_k)   # peut être vide si exit==entry

        # Série pleine sur tout l'horizon portefeuille
        ser = pd.Series(0.0, index=dates, dtype=float)
        if len(mtm) > 0:
            ser.loc[mtm.index] = mtm.values
            last_val = float(mtm.iloc[-1])
        else:
            last_val = 0.0

        # lock après exit
        ser.loc[ser.index > exit_] = last_val

        # (important) rester 0.0 avant et au jour d’entrée (déjà le cas)
        pnl_tracker[f"Trade_{i+1:03d}"] = ser

    pnl_tracker = pnl_tracker.fillna(0.0)  # sécurité
    pnl_tracker["CumPnL"] = pnl_tracker.sum(axis=1)

    return trades_df, pnl_tracker


# =========================
# 4) PLOTS PnL BACKTEST
# =========================
def plot_cum_pnl_realized(trades_df, title="Realized Cumulative PnL (k€) — by Exit"):
    if trades_df.empty:
        print("Pas de trades générés."); return
    plt.figure(figsize=(12,5))
    plt.plot(trades_df["Exit"], trades_df["RealizedCumPnL_by_exit"])
    plt.title(title); plt.xlabel("Exit date"); plt.ylabel("Cum PnL (k€)")
    plt.grid(True); plt.tight_layout(); plt.show()

def plot_portfolio_pnl(pnl_tracker, title="Portfolio PnL (mark-to-market)"):
    if pnl_tracker.empty:
        print("Pnl tracker vide."); return
    plt.figure(figsize=(12,5))
    plt.plot(pnl_tracker.index, pnl_tracker["CumPnL"])
    plt.title(title); plt.xlabel("Date"); plt.ylabel("Cum PnL (k€)")
    plt.grid(True); plt.tight_layout(); plt.show()


# =========================
# ====== EXEMPLES D’APPELS (séparés) ======
# =========================
# Hypothèse: `data` (index Datetime trié, colonnes "Country Matu" en %) existe dans le scope.

# # 0) MASTER (UNE SEULE FOIS). Fenêtre unique = ROLLING_WINDOW_DAYS
# master = build_master_dataframe(
#     data,
#     country_high=COUNTRY_HIGH,
#     country_low=COUNTRY_LOW,
#     matu_long=MATU_LONG,
#     matu_short=MATU_SHORT,
#     matu_spread=MATU_SPREAD,
#     curve_country=BENCHMARK_CURVE_COUNTRY,
#     window=ROLLING_WINDOW_DAYS
# )

# # 1) ANALYSE — NIVEAUX (BOX~SPREAD et BOX~CURVE)
# plot_rr_timeseries(master, "lvl", "spread", ROLLING_WINDOW_DAYS,
#     f"BOX vs SPREAD (Levels) — {COUNTRY_HIGH}-{COUNTRY_LOW} | {MATU_SHORT}s{MATU_LONG}")
# plot_rr_timeseries(master, "lvl", "curve",  ROLLING_WINDOW_DAYS,
#     f"BOX vs CURVE  (Levels) — {BENCHMARK_CURVE_COUNTRY} {MATU_SHORT}s{MATU_LONG}")
# # Scatter (levels): Beta vs niveaux SPREAD/CURVE (non filtré puis filtré par R²)
# plot_scatter_beta_year_heat(master, "lvl", "spread", ROLLING_WINDOW_DAYS,
#     x_on="SPREAD_bps", r2_min=None,
#     title="Beta (Levels: BOX~SPREAD) vs SPREAD level — ALL", x_label="Spread Level (bps)")
# plot_scatter_beta_year_heat(master, "lvl", "spread", ROLLING_WINDOW_DAYS,
#     x_on="SPREAD_bps", r2_min=R2_ENTRY_THRESHOLD,
#     title=f"Beta (Levels: BOX~SPREAD) vs SPREAD level — R²≥{R2_ENTRY_THRESHOLD}", x_label="Spread Level (bps)")

# # 2) ANALYSE — DAILY CHANGES (ΔBOX~ΔSPREAD & ΔBOX~ΔCURVE)
# plot_rr_timeseries(master, "chg", "spread", ROLLING_WINDOW_DAYS,
#     f"ΔBOX vs ΔSPREAD (Daily Changes) — {COUNTRY_HIGH}-{COUNTRY_LOW} | {MATU_SHORT}s{MATU_LONG}")
# plot_rr_timeseries(master, "chg", "curve",  ROLLING_WINDOW_DAYS,
#     f"ΔBOX vs ΔCURVE  (Daily Changes) — {BENCHMARK_CURVE_COUNTRY} {MATU_SHORT}s{MATU_LONG}")
# # Scatter demandé (daily changes): Beta(chg) vs **NIVEAU** du SPREAD (style heatmap par année)
# plot_scatter_beta_year_heat(master, "chg", "spread", ROLLING_WINDOW_DAYS,
#     x_on="SPREAD_bps", r2_min=None,
#     title="Beta (ΔBOX~ΔSPREAD) vs SPREAD level — ALL", x_label="Spread Level (bps)")
# plot_scatter_beta_year_heat(master, "chg", "spread", ROLLING_WINDOW_DAYS,
#     x_on="SPREAD_bps", r2_min=R2_ENTRY_THRESHOLD,
#     title=f"Beta (ΔBOX~ΔSPREAD) vs SPREAD level — R²≥{R2_ENTRY_THRESHOLD}", x_label="Spread Level (bps)")

# # 3) Plot simple BOX
# plot_box_level(master, title_suffix=f"— {COUNTRY_HIGH}-{COUNTRY_LOW} {MATU_SHORT}s{MATU_LONG}")

# # 4) BACKTEST (réutilise exactement les colonnes RR niveaux _w{ROLLING_WINDOW_DAYS})
# trades_df, pnl_tracker = backtest_from_master(
#     master,
#     obs_window_days=OBS_WINDOW_DAYS,
#     holding_days=HOLDING_DAYS,
#     resid_threshold=RESID_THRESHOLD,
#     r2_entry_threshold=R2_ENTRY_THRESHOLD,
#     tp_mult=TP_MULT, sl_mult=SL_MULT, dv01_k=DV01_K,
#     driver=DRIVER_FOR_SIGNAL   # "SPREAD" (ou "CURVE")
# )

# # Aperçus & plots
# print("=== trades_df (head) ==="); print(trades_df.head(10))
# print("=== pnl_tracker (head) ==="); print(pnl_tracker.head(10))
# plot_cum_pnl_realized(trades_df,
#     title=f"Realized Cumulative PnL (by Exit) — {COUNTRY_HIGH}-{COUNTRY_LOW} {MATU_SHORT}s{MATU_LONG} [{DRIVER_FOR_SIGNAL}]")
# plot_portfolio_pnl(pnl_tracker,
#     title=f"Portfolio MtM PnL — {COUNTRY_HIGH}-{COUNTRY_LOW} {MATU_SHORT}s{MATU_LONG} [{DRIVER_FOR_SIGNAL}]")

